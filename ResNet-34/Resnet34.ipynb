{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":100293,"databundleVersionId":12025815,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n## import numpy as np # linear algebra\n## import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n## import os\n## for dirname, _, filenames in os.walk('/kaggle/input'):\n##    for filename in filenames:\n##        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:47:51.846798Z","iopub.execute_input":"2025-05-12T21:47:51.847557Z","iopub.status.idle":"2025-05-12T21:47:51.851311Z","shell.execute_reply.started":"2025-05-12T21:47:51.847522Z","shell.execute_reply":"2025-05-12T21:47:51.850318Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nfrom collections import Counter\n\ndata_dir = '/kaggle/input/fine-grained-fruit-quality-assessment/train/train'\n\nclass_counts = {}\n\nfor class_name in os.listdir(data_dir):\n    class_folder = os.path.join(data_dir, class_name)\n    if os.path.isdir(class_folder):\n        num_images = len(os.listdir(class_folder))\n        class_counts[class_name] = num_images\n\ntotal_images = sum(class_counts.values())\n\nclass_proportions = {class_name: count / total_images for class_name, count in class_counts.items()}\n\nprint(\"Class Proportions:\")\nfor class_name, proportion in class_proportions.items():\n    print(f\"{class_name}: {proportion:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:47:51.857023Z","iopub.execute_input":"2025-05-12T21:47:51.857264Z","iopub.status.idle":"2025-05-12T21:47:51.877318Z","shell.execute_reply.started":"2025-05-12T21:47:51.857247Z","shell.execute_reply":"2025-05-12T21:47:51.876708Z"}},"outputs":[{"name":"stdout","text":"Class Proportions:\ntomato_fully_ripened: 0.01\ntomato_half_ripened: 0.01\nbanana_overripe: 0.21\nbanana_rotten: 0.30\nbanana_unripe: 0.21\nbanana_ripe: 0.22\ntomato_green: 0.05\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#resizing\nIMG_SIZE = (224, 224)\n#scaling and splits\ndata = ImageDataGenerator(rescale=1./255, validation_split=0.2)#stratified splits for unbalanced data\n\ntrainData = data.flow_from_directory(\n    '/kaggle/input/fine-grained-fruit-quality-assessment/train/train',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='sparse',#uses label encoding\n    shuffle=True,\n    subset='training'\n)\n\nvalData = data.flow_from_directory(\n    '/kaggle/input/fine-grained-fruit-quality-assessment/train/train',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='sparse',\n    shuffle=False,\n    subset='validation'\n)\n\ntestData = data.flow_from_directory(\n    '/kaggle/input/fine-grained-fruit-quality-assessment/test',\n    target_size=IMG_SIZE,\n    batch_size=32,\n    class_mode='sparse',\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:47:51.878451Z","iopub.execute_input":"2025-05-12T21:47:51.878708Z","iopub.status.idle":"2025-05-12T21:47:58.829797Z","shell.execute_reply.started":"2025-05-12T21:47:51.878685Z","shell.execute_reply":"2025-05-12T21:47:58.829013Z"}},"outputs":[{"name":"stderr","text":"2025-05-12 21:47:52.183786: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747086472.206626    1931 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747086472.213590    1931 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Found 5917 images belonging to 7 classes.\nFound 1478 images belonging to 7 classes.\nFound 2484 images belonging to 1 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, Model\n\n\n\ndef convolutionBlock(x, filters, kernel_size=3, strides=1):\n    x = layers.Conv2D(filters, kernel_size, strides=strides, padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    return layers.ReLU()(x)\n\ndef residuals(x, filters, downsample=False):\n    shortcut = x\n    strides = 2 if downsample else 1\n\n    x = convolutionBlock(x, filters, strides=strides)\n    x = layers.Conv2D(filters, 3, strides=1, padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n\n    if downsample or x.shape[-1] != shortcut.shape[-1]:\n        shortcut = layers.Conv2D(filters, 1, strides=strides, use_bias=False)(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    x = layers.Add()([x, shortcut])\n    return layers.ReLU()(x)\n\n\n\ndef ResNet34(inputShape=(224, 224, 3), num_classes=7):\n    \n    inputs = layers.Input(shape=inputShape)\n    x = convolutionBlock(inputs, 64, kernel_size=7, strides=2)\n    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n\n    for filters, blocks, downsample in zip([64, 128, 256, 512], [3, 4, 6, 3], [False, True, True, True]):\n        for i in range(blocks):\n            x = residuals(x, filters, downsample=(i == 0 and downsample))\n\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(num_classes, activation='softmax')(x)\n    return Model(inputs, x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:47:58.830638Z","iopub.execute_input":"2025-05-12T21:47:58.831195Z","iopub.status.idle":"2025-05-12T21:47:58.839184Z","shell.execute_reply.started":"2025-05-12T21:47:58.831172Z","shell.execute_reply":"2025-05-12T21:47:58.838411Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras import layers, regularizers, Model\n\nbase_model = ResNet34(inputShape=(224, 224, 3), num_classes=7)\n\n# x = base_model.layers[-2].output  # or base_model.output if needed\n\n# x = layers.Dense(512, kernel_regularizer=regularizers.l2(0.01))(x)\n# x = layers.LeakyReLU(alpha=0.1)(x)\n# x = layers.Dropout(0.5)(x)\n\n# x = layers.Dense(256, kernel_regularizer=regularizers.l2(0.01))(x)\n# x = layers.LeakyReLU(alpha=0.1)(x)\n# x = layers.Dropout(0.3)(x)\n\n# outputs = layers.Dense(7, activation='softmax')(x)\n\n\nx = base_model.layers[-2].output  # or base_model.output if -2 doesn't fit your architecture\nx = layers.Dense(512, kernel_regularizer=regularizers.l2(0.01))(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(alpha=0.1)(x)\nx = layers.Dropout(0.5)(x)\n\nx = layers.Dense(256, kernel_regularizer=regularizers.l2(0.01))(x)\nx = layers.BatchNormalization()(x)\nx = layers.LeakyReLU(alpha=0.1)(x)\nx = layers.Dropout(0.3)(x)\n\noutputs = layers.Dense(7, activation='softmax')(x)\n\n# x = base_model.layers[-2].output\n# x = layers.Dense(512, activation='relu')(x)\n# x = layers.Dropout(0.5)(x)\n# x = layers.Dense(256, activation='relu')(x)\n# x = layers.Dropout(0.3)(x)\n# outputs = layers.Dense(7, activation='softmax')(x)\n\n# x = base_model.layers[-2].output\n# x = layers.Dense(256, activation='relu')(x)\n# x = layers.Dropout(0.5)(x)\n# outputs = layers.Dense(7, activation='softmax')(x)\n\nfinalModel = Model(inputs=base_model.input, outputs=outputs)\n\nfinalModel.compile(optimizer='adam',\n                     loss='sparse_categorical_crossentropy',\n                     metrics=['accuracy'])\n\nfinalModel.fit(trainData, validation_data=valData, epochs=20)\n\nfinalModel.save_weights('/kaggle/working/ResNet34.weights.h5')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T21:47:58.840585Z","iopub.execute_input":"2025-05-12T21:47:58.840842Z","iopub.status.idle":"2025-05-12T22:08:45.706893Z","shell.execute_reply.started":"2025-05-12T21:47:58.840823Z","shell.execute_reply":"2025-05-12T22:08:45.706000Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1747086479.229576    1931 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1747086479.230237    1931 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1747086509.008949    2004 service.cc:148] XLA service 0x7a3044062e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1747086509.008996    2004 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1747086509.009000    2004 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1747086511.426700    2004 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1747086523.771558    2004 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 405ms/step - accuracy: 0.6078 - loss: 7.4153 - val_accuracy: 0.4777 - val_loss: 5.2806\nEpoch 2/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 320ms/step - accuracy: 0.7731 - loss: 2.1419 - val_accuracy: 0.6353 - val_loss: 1.6622\nEpoch 3/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 322ms/step - accuracy: 0.8119 - loss: 1.0719 - val_accuracy: 0.3945 - val_loss: 2.0707\nEpoch 4/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 321ms/step - accuracy: 0.8413 - loss: 0.7313 - val_accuracy: 0.6976 - val_loss: 1.0095\nEpoch 5/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 318ms/step - accuracy: 0.8420 - loss: 0.6380 - val_accuracy: 0.3694 - val_loss: 4.7951\nEpoch 6/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 306ms/step - accuracy: 0.8721 - loss: 0.5660 - val_accuracy: 0.5765 - val_loss: 1.3702\nEpoch 7/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 307ms/step - accuracy: 0.8744 - loss: 0.5082 - val_accuracy: 0.6867 - val_loss: 1.2970\nEpoch 8/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 295ms/step - accuracy: 0.8648 - loss: 0.5606 - val_accuracy: 0.5731 - val_loss: 1.9527\nEpoch 9/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 292ms/step - accuracy: 0.8773 - loss: 0.4944 - val_accuracy: 0.6319 - val_loss: 1.4715\nEpoch 10/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 305ms/step - accuracy: 0.8816 - loss: 0.4676 - val_accuracy: 0.7760 - val_loss: 0.8014\nEpoch 11/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 307ms/step - accuracy: 0.8792 - loss: 0.4860 - val_accuracy: 0.3742 - val_loss: 4.0175\nEpoch 12/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 302ms/step - accuracy: 0.8982 - loss: 0.4372 - val_accuracy: 0.1840 - val_loss: 3.7360\nEpoch 13/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 312ms/step - accuracy: 0.8922 - loss: 0.4471 - val_accuracy: 0.8606 - val_loss: 0.5896\nEpoch 14/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 318ms/step - accuracy: 0.8918 - loss: 0.4375 - val_accuracy: 0.6441 - val_loss: 1.1942\nEpoch 15/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 294ms/step - accuracy: 0.9098 - loss: 0.4100 - val_accuracy: 0.2382 - val_loss: 3.3051\nEpoch 16/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 319ms/step - accuracy: 0.9058 - loss: 0.4133 - val_accuracy: 0.9046 - val_loss: 0.4084\nEpoch 17/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 308ms/step - accuracy: 0.9112 - loss: 0.3987 - val_accuracy: 0.5656 - val_loss: 3.1160\nEpoch 18/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 309ms/step - accuracy: 0.9117 - loss: 0.3910 - val_accuracy: 0.7612 - val_loss: 0.7458\nEpoch 19/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 310ms/step - accuracy: 0.9073 - loss: 0.4039 - val_accuracy: 0.8836 - val_loss: 0.4954\nEpoch 20/20\n\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 308ms/step - accuracy: 0.9166 - loss: 0.3582 - val_accuracy: 0.9154 - val_loss: 0.3575\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"finalModel.load_weights('/kaggle/working/ResNet34.weights.h5')\n\nval_loss, val_accuracy = finalModel.evaluate(valData)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:08:45.708019Z","iopub.execute_input":"2025-05-12T22:08:45.708405Z","iopub.status.idle":"2025-05-12T22:08:58.954778Z","shell.execute_reply.started":"2025-05-12T22:08:45.708362Z","shell.execute_reply":"2025-05-12T22:08:58.953930Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 269ms/step - accuracy: 0.9239 - loss: 0.3424\nValidation Accuracy: 0.9154\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\n\npredicted_classes = tf.argmax(finalModel.predict(testData), axis=1)\n\nfilenames = testData.filenames\n\ndf_predictions = pd.DataFrame({\n    'ImageID': [os.path.basename(f) for f in filenames],\n    'Class': predicted_classes\n})\n\n\ndf_predictions.to_csv('/kaggle/working/test_predictions.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T22:13:57.561675Z","iopub.execute_input":"2025-05-12T22:13:57.561970Z","iopub.status.idle":"2025-05-12T22:14:13.051923Z","shell.execute_reply.started":"2025-05-12T22:13:57.561946Z","shell.execute_reply":"2025-05-12T22:14:13.051378Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 194ms/step\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}